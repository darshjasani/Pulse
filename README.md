# âš¡ Pulse

**Scalable Social Feed Platform** - A production-style system design project demonstrating distributed systems concepts, event-driven architecture, and cloud-native design patterns.

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.109+-green.svg)](https://fastapi.tiangolo.com/)
[![AWS](https://img.shields.io/badge/AWS-Ready-orange.svg)](https://aws.amazon.com/)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://www.docker.com/)

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [System Architecture](#-system-architecture)
- [Key Features](#-key-features)
- [Technology Stack](#-technology-stack)
- [Quick Start](#-quick-start)
- [API Documentation](#-api-documentation)
- [System Design Deep Dive](#-system-design-deep-dive)
- [AWS Deployment](#-aws-deployment)
- [Demo Scenarios](#-demo-scenarios)
- [Performance & Scaling](#-performance--scaling)
- [Tradeoffs & Design Decisions](#-tradeoffs--design-decisions)

---

## ğŸ¯ Overview

Pulse is a social feed platform built to demonstrate **real-world system design concepts** used by companies like Twitter, Instagram, and Facebook. It showcases:

- **Hybrid Push-Pull Timeline Architecture**
- **Event-Driven Fan-out Pattern**
- **Celebrity Problem Solution**
- **Multi-tier Caching Strategy**
- **Graceful Degradation**
- **Cloud-Native Design**

### Problem Statement

Modern social platforms must serve **low-latency personalized feeds** while handling:
- High read traffic (millions of timeline requests/sec)
- Write amplification (one post â†’ millions of timelines)
- Hot users (celebrities with millions of followers)
- Service failures without downtime

**Pulse demonstrates production-grade solutions to these challenges.**

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client    â”‚
â”‚   (Web UI)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         FastAPI Application             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Auth   â”‚  Users   â”‚    Posts     â”‚ â”‚
â”‚  â”‚ Service â”‚ Service  â”‚   Service    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚      Timeline Service            â”‚  â”‚
â”‚  â”‚  (Hybrid Push-Pull Strategy)     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
    â”‚              â”‚              â”‚
    â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Redis   â”‚  â”‚   SQS    â”‚  â”‚PostgreSQLâ”‚
â”‚ (Cache) â”‚  â”‚ (Queue)  â”‚  â”‚   (DB)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  Fan-out     â”‚
           â”‚   Worker     â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

**Write Path (Normal User):**
1. User creates post â†’ Saved to PostgreSQL
2. Event published to SQS queue
3. Fan-out worker consumes event
4. Post pushed to all follower timelines in Redis
5. ~200ms total latency

**Write Path (Celebrity):**
1. User creates post â†’ Saved to PostgreSQL
2. **No fan-out** (write amplification avoided)
3. ~10ms total latency

**Read Path:**
1. Request timeline â†’ Check Redis cache
2. If cache hit â†’ Return immediately (~50ms)
3. Pull celebrity posts (always fresh)
4. Merge & sort by timestamp
5. If cache miss â†’ Fallback to database (~200ms)

---

## âœ¨ Key Features

### 1. **Hybrid Timeline Architecture**
- **Push Model**: Fan-out for normal users (fast reads)
- **Pull Model**: On-demand for celebrities (prevents write amplification)
- Best of both worlds

### 2. **Celebrity Detection**
- Automatic threshold detection (100K+ followers)
- Dynamic flag update
- Separate handling logic

### 3. **Event-Driven Fan-out**
- Asynchronous processing via SQS
- Retry logic & idempotency
- Decoupled architecture

### 4. **Graceful Degradation**
- Redis down? Fall back to database
- SQS unavailable? Direct timeline write
- Always operational

### 5. **Production-Ready Code**
- Type hints & validation (Pydantic)
- Proper error handling
- Logging & observability
- Security (JWT, password hashing)

---

## ğŸ› ï¸ Technology Stack

### Backend
- **FastAPI** - Modern Python web framework
- **SQLAlchemy** - ORM for database operations
- **PostgreSQL** - Primary data store
- **Redis** - Timeline cache & sorted sets
- **Pydantic** - Data validation

### Infrastructure
- **Docker** - Containerization
- **Docker Compose** - Local orchestration
- **AWS SQS** - Message queue
- **AWS RDS** - Managed PostgreSQL (optional)
- **AWS EC2** - Compute (for demo)

### Frontend
- **Vanilla JavaScript** - Simple, dependency-free UI
- **HTML/CSS** - Modern responsive design

---

## ğŸš€ Quick Start

### Prerequisites
- Docker & Docker Compose
- Python 3.11+
- (Optional) AWS Account for cloud demo

### Local Setup (5 Minutes)

```bash
# Clone the repository
cd Pulse

# Run automated setup
chmod +x scripts/setup_local.sh
./scripts/setup_local.sh

# Start the API
uvicorn services.main:app --reload

# In another terminal, start the worker
python -m workers.fanout_worker

# Open the UI
open ui/index.html
# Or visit: http://localhost:8000/docs
```

**Demo Credentials:**
- Username: `alice`, Password: `password123`
- Username: `bob`, Password: `password123`
- Username: `celebrity_user`, Password: `password123`

### Manual Setup

```bash
# 1. Create .env file
cp .env.example .env

# 2. Start infrastructure
docker-compose up -d postgres redis

# 3. Install dependencies
pip install -r requirements.txt

# 4. Initialize database
python scripts/init_db.py

# 5. Seed demo data
python scripts/seed_demo_data.py

# 6. Start services
uvicorn services.main:app --reload
python -m workers.fanout_worker
```

---

## ğŸ“š API Documentation

### Authentication

**Sign Up**
```http
POST /auth/signup
Content-Type: application/json

{
  "username": "john",
  "email": "john@example.com",
  "password": "password123"
}
```

**Login**
```http
POST /auth/login
Content-Type: application/json

{
  "username": "john",
  "password": "password123"
}

Response:
{
  "access_token": "eyJ0eXAiOiJKV1QiLCJhbGc...",
  "token_type": "bearer"
}
```

### Posts

**Create Post**
```http
POST /posts
Authorization: Bearer {token}
Content-Type: application/json

{
  "content": "Hello, Pulse!"
}
```

**Get Timeline**
```http
GET /timeline
Authorization: Bearer {token}

Response:
{
  "posts": [...],
  "source": "cache",  // or "database"
  "has_more": true
}
```

### Social

**Follow User**
```http
POST /users/follow/{user_id}
Authorization: Bearer {token}
```

**Get Followers**
```http
GET /users/{user_id}/followers
```

### System

**Health Check**
```http
GET /system/health

Response:
{
  "status": "healthy",
  "database": "healthy",
  "redis": "healthy",
  "timestamp": "2025-01-02T..."
}
```

**Metrics**
```http
GET /system/metrics

Response:
{
  "total_users": 150,
  "total_posts": 1200,
  "celebrity_users": 5,
  "redis_available": true
}
```

**Full API Documentation:** http://localhost:8000/docs

---

## ğŸ“ System Design Deep Dive

### The Celebrity Problem

**Problem:** A celebrity with 10M followers posts â†’ 10M timeline writes â†’ Database overload

**Traditional Approach (Push Only):**
- âŒ Write amplification: 1 write â†’ 10M writes
- âŒ Slow: Takes minutes to fan-out
- âŒ Expensive: High compute & storage costs

**Our Solution (Hybrid):**
- âœ… **Push for normal users** (< 100K followers)
  - Fast reads (cached)
  - Acceptable write cost
- âœ… **Pull for celebrities** (> 100K followers)
  - No fan-out
  - Fetched at read time
  - Fresh & accurate

### Timeline Architecture

**Sorted Sets in Redis:**
```python
Key: "timeline:{user_id}"
Value: Sorted Set
  - Member: post_id
  - Score: timestamp

ZADD timeline:123 1704268800.0 "post_456"
ZREVRANGE timeline:123 0 49  # Get 50 latest
```

**Why Sorted Sets?**
- O(log N) insertion
- O(log N) range queries
- Automatic sorting by timestamp
- Memory efficient

### Fan-out Strategy

**Decision Matrix:**
```
User Type    | Follower Count | Strategy      | Write Cost | Read Cost
-------------|----------------|---------------|------------|----------
Normal       | < 100K         | Push (Fan-out)| Medium     | Low (cached)
Celebrity    | > 100K         | Pull (On-read)| Low        | Medium
```

**Implementation:**
```python
if not user.is_celebrity:
    # Fan-out to followers
    sqs.publish_event(post_id)
    worker.fan_out_to_followers()
else:
    # Skip fan-out, will be pulled
    pass
```

### Caching Strategy

**L1 Cache (Redis):**
- Timeline sorted sets
- TTL: Infinite (size-limited to 1000 posts)
- Eviction: ZREMRANGEBYRANK

**Cache Invalidation:**
- **On Follow:** Clear follower's timeline
- **On Unfollow:** Clear follower's timeline
- **On Post Delete:** Remove from all timelines (async)

**Fallback Chain:**
```
Request â†’ Redis Cache â†’ PostgreSQL â†’ Return
            â†“ Hit (50ms)   â†“ Miss (200ms)
```

---

## â˜ï¸ AWS Deployment

### Setup AWS Resources

```bash
# Configure AWS credentials
aws configure

# Create SQS queue and update .env
./scripts/setup_aws.sh

# Update .env with your credentials
AWS_ACCESS_KEY_ID=your_key
AWS_SECRET_ACCESS_KEY=your_secret
SQS_QUEUE_URL=https://sqs.us-east-1.amazonaws.com/...
```

### Architecture with AWS

```
Local Machine:
  â”œâ”€â”€ FastAPI (API Server)
  â””â”€â”€ Worker (Fan-out)
       â”‚
       â”œâ”€â†’ AWS RDS (PostgreSQL)
       â”œâ”€â†’ AWS SQS (Message Queue)
       â””â”€â†’ Redis (EC2 or ElastiCache)
```

### Cost Estimate (Monthly)

| Service | Configuration | Cost |
|---------|---------------|------|
| RDS     | db.t3.micro   | $15  |
| SQS     | 1M requests   | Free |
| EC2     | t2.micro (Redis) | $8  |
| **Total** |             | **~$25** |

**Stop instances when not demoing to save costs!**

---

## ğŸ¬ Demo Scenarios

### Scenario 1: Normal User Flow

```bash
# 1. Login as Alice
POST /auth/login {"username": "alice", "password": "password123"}

# 2. Create a post
POST /posts {"content": "Hello, Pulse!"}

# 3. Check Bob's timeline (who follows Alice)
GET /timeline (as Bob)
# Expected: Alice's post appears (from cache)

# 4. Check metrics
GET /system/metrics
# Show: Redis available, source = "cache"
```

### Scenario 2: Celebrity User

```bash
# 1. Login as celebrity_user (100K+ followers)
POST /auth/login {"username": "celebrity_user", ...}

# 2. Create a post
POST /posts {"content": "Celebrity announcement!"}
# Expected: No fan-out event (check logs)

# 3. View timeline as follower
GET /timeline (as Alice)
# Expected: Celebrity post appears (pulled at read time)
```

### Scenario 3: Graceful Degradation

```bash
# 1. Stop Redis
docker-compose stop redis

# 2. Request timeline
GET /timeline
# Expected: Still works, source = "database", slower

# 3. Check health
GET /system/health
# Shows: Redis "unavailable", Database "healthy"

# 4. Restart Redis
docker-compose start redis
# System recovers automatically
```

---

## ğŸ“Š Performance & Scaling

### Current Performance

- **Timeline Read (Cached):** ~50ms P95
- **Timeline Read (DB):** ~200ms P95
- **Post Write (Normal):** ~150ms P95
- **Post Write (Celebrity):** ~10ms P95

### Scaling Strategies

**Horizontal Scaling:**
```
Load Balancer
    â”œâ”€â”€ API Server 1
    â”œâ”€â”€ API Server 2
    â””â”€â”€ API Server 3
         â†“
    (Stateless, share Redis & DB)
```

**Database Scaling:**
- Read replicas for timeline queries
- Sharding by user_id
- Connection pooling (already implemented)

**Cache Scaling:**
- Redis Cluster (16K slots)
- Shard by user_id hash
- Read replicas for hot keys

**Worker Scaling:**
- Multiple workers reading from SQS
- Auto-scaling based on queue depth
- Dead letter queue for failures

### Bottlenecks & Mitigations

| Bottleneck | Symptom | Solution |
|------------|---------|----------|
| DB Writes | Slow post creation | Write buffer, async commits |
| Redis Memory | OOM errors | TTL, size limits, eviction policy |
| Fan-out Lag | Stale timelines | More workers, batch writes |
| Celebrity Reads | Slow timelines | Separate cache, CDN |

---

## âš–ï¸ Tradeoffs & Design Decisions

### 1. **Eventual Consistency**

**Decision:** Timelines are eventually consistent

**Why:**
- CAP Theorem: Choose Availability + Partition Tolerance
- Acceptable for social feeds (not financial data)
- Enables horizontal scaling

**Tradeoff:**
- âœ… High availability
- âœ… Better performance
- âŒ Brief inconsistency (seconds)

### 2. **Push vs. Pull**

**Decision:** Hybrid approach based on follower count

**Why:**
- Best of both worlds
- Optimizes for common case (normal users)
- Handles edge case (celebrities)

**Tradeoff:**
- âœ… Balanced write/read costs
- âœ… Scalable
- âŒ More complexity

### 3. **Redis for Timelines**

**Decision:** Use Redis sorted sets for timeline cache

**Why:**
- In-memory â†’ very fast reads
- Sorted sets â†’ natural fit for timelines
- Simple data structure

**Tradeoff:**
- âœ… Sub-50ms reads
- âœ… Simple implementation
- âŒ Memory cost
- âŒ Data loss on crash (acceptable)

### 4. **SQS for Events**

**Decision:** Use message queue for fan-out

**Why:**
- Decouples API from worker
- Built-in retry & DLQ
- Managed service (no ops)

**Tradeoff:**
- âœ… Reliability
- âœ… Scalability
- âŒ AWS dependency
- âŒ Latency (seconds)

### 5. **No Pagination (Yet)**

**Decision:** Simple offset/limit pagination

**Why:**
- Sufficient for demo
- Easy to understand

**Production would use:**
- Cursor-based pagination
- Prevents skipped/duplicate posts
- Better for real-time feeds

---

## ğŸ§ª Testing

```bash
# Run tests (coming soon)
pytest

# Load testing
# Install: pip install locust
locust -f tests/load_test.py
```

---

## ğŸ¤ Contributing

This is a demo project, but feedback and improvements are welcome!

---

## ğŸ“„ License

MIT License - Feel free to use for learning and demos

---

## ğŸ¤ Presenting This Project

### Key Talking Points

1. **"I built a scalable social feed platform demonstrating production-grade system design."**

2. **"The celebrity problem is a classic distributed systems challenge - I solved it with a hybrid push-pull architecture."**

3. **"Notice how I prioritize availability over consistency - this is a deliberate CAP theorem choice."**

4. **"The system gracefully degrades - Redis goes down, we fall back to database. No hard failures."**

5. **"I can scale horizontally - the API is stateless, workers are stateless, everything can be replicated."**

### Demo Script (5 Minutes)

**Minute 1:** Architecture overview (diagram)

**Minute 2:** Normal user flow (Alice posts â†’ Bob's timeline)

**Minute 3:** Celebrity flow (no fan-out, explain why)

**Minute 4:** Failure handling (kill Redis, still works)

**Minute 5:** Scaling discussion (how to 10x, 100x)

---

## ğŸ“ Contact

**Project:** Pulse - Scalable Social Feed Platform

**Purpose:** System Design Interview Preparation

**Built with:** FastAPI, PostgreSQL, Redis, AWS SQS, Docker

---

**âš¡ Now go build something amazing!**

